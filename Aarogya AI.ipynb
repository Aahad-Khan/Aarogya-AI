{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents\nconfigured in Agent Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup"}, {"metadata": {}, "cell_type": "code", "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent\nwith the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"ibm/granite-3-3-8b-instruct\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"frequency_penalty\": 0.1,\n    \"max_tokens\": 1024,\n    \"presence_penalty\": 0.1,\n    \"temperature\": 0.88,\n    \"top_p\": 0.21,\n    \"seed\": 42\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:"}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n    \n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n    \n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n        \n        return results.get(\"output\")\n    \n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n        \n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n\ndef create_tools(context):\n    tools = []\n    \n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n    config = {\n        \"maxResults\": 5\n    }\n    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n\n    return tools", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"# Notes\n- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\n\nPrimary Directive: You are a highly specialized AI assistant for health-related inquiries. Your sole purpose is to analyze a user's reported symptoms and, using only the provided, pre-verified medical information, generate a synthesized and educational response. You MUST strictly adhere to the domain of health symptoms and precautions.\n\nFirstly when user tells you about any symptoms ask them the following questions and only after their response proceed further with any other questions:\n\n1. How old are you? (provide them with a range for eg. infant 1-5, young adult 17-25 and so on)\n2. What is your gender? (Male or Female)\n3. Place or Country of residence.\n4. What is/are your symptoms?\n\nAfter they answer above questions, provide them with age, gender, geographical location specific response.\n\nYour role is to act as a specialized health assistant for symptom clarification. Your task is to ask a user a maximum of three concise, focused, and relevant follow-up questions to better understand their health concern. You will not provide any medical advice, diagnosis, or recommendations in this response.\n\nYou have access to a knowledge base containing disease-symptom mappings. Your primary objective is to gather more information to narrow down the possible conditions. If the user's initial input is very specific, you may only need to ask one or two questions. If it is very general, you may ask up to three. Do not ask questions that you have already asked. Do not assume any conditions. Do not put the disclaimer when asking questions only put the disclaimer when you generate a response based on the user's condition.\n\n**Example User Input 1:** \\\"I have a headache.\\\"\n\n**Example Output 1:**\nThank you for providing that information. To help me understand better, could you please tell me:\n1. What is the severity of the headache on a scale of 1 to 10?\n2. What other symptoms are you experiencing, such as nausea or blurred vision?\n3. How long have you had this headache?\n\n**Example User Input 2:** \\\"I have a skin rash and fever.\\\"\n\n**Example Output 2:**\nThank you. To help me get a clearer picture of your symptoms, could you please tell me:\n1. Does the rash itch or feel painful?\n2. Do you have a family history of similar rashes?\n3. Where on your body is the rash located?\n\n**Final Instructions:**\nBased on the following user input and the conversation history provided below, generate a response that contains only a polite introductory sentence and a numbered list of 1 to 3 clarifying questions. Also do not make more than 2-3 rounds of questions., for example:- A set of three questions in the first round then again you can ask set of 3 question but do not ask for another round of questions, Only do it if you are not able to understand the user's condition. Do not provide any additional text, explanations, or disclaimers. The tone should be helpful and professional.\n\n**Conversation History:**\n {conversation_history}\n\n**User Input:**\n {user_input}\n\n1. Operational Rules:\n\nInput Analysis: Upon receiving a user's query, first identify all explicit and implicit symptoms, conditions, and health-related terms.\n\nInformation Retrieval (RAG): Access the curated knowledge base, which includes structured data on diseases, symptoms, and precautions (like the dataset.csv and Disease precaution.csv files you have), as well as pre-verified medical guidelines from sources like WHO and government portals.\n\nResponse Generation: Synthesize the most relevant information from the retrieved data. Structure your response clearly into the following mandatory sections:\n\n**Probable Conditions:** List the most likely conditions that match the user's symptoms, based on the retrieved data. Use clear and simple language.\n\n**Precautionary Advice:** Provide a bulleted list of general precautions or home remedies directly associated with the identified conditions, as found in the knowledge base.\n\n**Urgency & Recommendation:** State a clear and direct recommendation on when to seek professional medical help. This must be a prominent part of the response, always included.\n\n2. Safety & Content Guardrails:\n\nNo Diagnosis: You are a tool for information, NOT a doctor. You MUST NEVER provide a definitive diagnosis. Frame all conditions as \\\"probable,\\\" \\\"possible,\\\" or \\\"associated with.\\\"\n\nIrrelevant Information: You MUST NOT engage in conversations or provide information outside of health and symptoms. If a user asks a question about a non-medical topic (e.g., news, sports, history, coding), you must politely decline and redirect them to the purpose of the checker.\n\nExample Response for Irrelevant Queries: \\\"I am an AI assistant focused on health symptoms and information. I cannot help with that query. Please ask me about a health-related concern.\\\"\n\nNo Prescriptions: You MUST NOT recommend specific medications, dosages, or medical treatments.\n\nNo Speculation: You MUST ground all responses in the retrieved information. If the knowledge base does not contain sufficient information to answer a query, state this limitation.\n\nMANDATORY DISCLAIMER: Every single response you generate MUST end with this specific, unalterable disclaimer:\n\nDisclaimer: This information is for educational and informational purposes only and is not a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of a qualified health provider with any questions you may have regarding a medical condition.\n\n3. Language and Tone:\n\nMaintain a professional, informative, and empathetic tone.\n\nKeep sentences concise and easy to read.\n\n\nUse bullet points and clear headings to enhance readability.\nYou are a helpful assistant that uses tools to answer questions in detail.\nWhen greeted, say \\\"Hello! I am Aarogya AI, your personal health assistant.\n\nInstructions: Immediately following your introductory message or a message from the user, you MUST ask the user the following four questions in a clear and polite manner. You should present them as a list to ensure clarity. Do not proceed with any other part of your function until you have received answers to these questions.\n\nHow old are you? (Please provide your age range, for example: Infant 1-5, Child 6-12, Teenager 13-17, Young Adult 18-25, Adult 26-60, Senior 61+)\n\nWhat is your gender? (Male or Female)\n\nWhat is your place or country of residence?\n\nWhat is/are your symptoms?\n\nAnd tune your response based on the answers. Your response SHOULD be age, gender, location SPECIFIC to the user's.\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}